{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LUng Nodule Analysis 2016 (LuNA 16) Dataset\n",
    "\n",
    "## Dataset\n",
    "\n",
    "### [Download](https://luna16.grand-challenge.org/Download/)\n",
    "\n",
    "This dataset is based on the publicly available [LIDC/IDRI database](https://wiki.cancerimagingarchive.net/display/Public/LIDC-IDRI).\n",
    "\n",
    "Data can be downloaded [here](https://luna16.grand-challenge.org/Download/). Data consist of two major parts located in [part1](https://zenodo.org/records/3723295) and [part2](https://zenodo.org/records/4121926). This link provide the data and a lot of different metadata for this dataset. The main data consists of ten subsets. Because full dataset has approximately 220gb, I will be using just subsets from 1 to 3 in my local environment. Then, I want to use Azure ML to train my dataset on full data using it's GPU VM. \n",
    "\n",
    "### [Description](https://luna16.grand-challenge.org/Data/)\n",
    "\n",
    "The data is structured as follows:\n",
    "- **subset0.zip to subset9.zip**: 10 zip files which contain all CT images\n",
    "- **annotations.csv**: csv file that contains the annotations used as reference standard for the 'nodule detection' track\n",
    "- **sampleSubmission.csv**: an example of a submission file in the correct format\n",
    "- **candidates.csv**: the original set of candidates used for the LUNA16 workshop at ISBI2016. This file is kept for completeness, but should not be used, use candidates_V2.csv instead (see more info below).\n",
    "- **candidates_V2.csv**: csv file that contains an extended set of candidate locations for the ‘false positive reduction’ track. \n",
    "- **evaluation script**: the evaluation script that is used in the LUNA16 framework\n",
    "- **lung segmentation**: a directory that contains the lung segmentation for CT images computed using automatic algorithms\n",
    "- **additional_annotations.csv**: csv file that contain additional nodule annotations from our observer study. The file will be available soon\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describing Data structures\n",
    "\n",
    "The 10 subsets we discussed earlier have about 90 CT scans each (888 in total), with every CT scan represented as two files: one with a `.mhd` extension and one with a `.raw` extension. The data being split between multiple files is hidden behind the `sitk` routines, however, and is not something we need to be directly concerned with.\n",
    "\n",
    "### Series UID\n",
    "\n",
    "We identify specific CT scans using the **series instance UID** (**series_uid**) assigned when the CT scan was created. DICOM makes heavy use of unique identifiers (UIDs) for individual DICOM files, groups of files, courses of treatment, and so on.\n",
    "\n",
    "`seriesuid` is property that is in both `candidates.csv` and `annotations.csv`. It uniquely identifies CT scan. But metadata assigned to this scans does not need to be unique. Both candidates and annotations dataframes are not unique on `seriesuid`. Candidates file contains center point of potential nodule and info if it is nodule or just lump. Annotation file contains center point of indemnified nodule and diameter of this nodule. CT scan can have multiple nodules and thus both of this dataframes can he multiple rows with the same `seriesuid`.\n",
    "\n",
    "> **Series UID** identifiers are similar in concept to [UUIDs](https://docs.python.org/3/library/uuid.html), but they have a different creation process and are formatted differently. For our purposes, we can treat them as opaque ASCII strings that serve as unique keys to reference the various CT scans. Officially, only the characters $0$ through $9$ and the period (.) are valid characters in a DICOM UID, but some DICOM files in the wild have been anonymized with routines that replace the UIDs with hexadecimal (0–9 and a–f) or other technically out-of-spec values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Evaluation vs. Deep Learning \n",
    "\n",
    "The majority of a CT scan does not contribute to determining whether a patient has a malignant tumor. This is because most of the patient's body consists of healthy cells. Even in cases where a malignant tumor is present, up to 99.9999% of the voxels in the CT scan will not indicate cancer. This ratio is comparable to a two-pixel error on a high-definition television screen or a single misspelled word in a shelf full of novels.\n",
    "\n",
    "<figure>\n",
    "    <center>\n",
    "        <img src=\"attachments/ct-scan-visualization.png\"  style=\"width:750px;\" >\n",
    "    </center>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-End versus Specific Model Design \n",
    "\n",
    "End-to-end models (e.g. Fast R-CNN, Mask R-CNN from TorchVision) perform well in general vision tasks but require vast datasets—impractical for rare classes. Our approach effectively handles modest data. Collecting immense data for training is resource-intensive and often yields poor results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain Knowledge\n",
    "\n",
    "## Computed Tomography (CT) Scan\n",
    "\n",
    "We will be using data from CT scans extensively as the main data format for our project. CT scans are essentially 3D X-rays, represented as a 3D array of single-channel data. Each element in the array is called a voxel, which is the 3D equivalent of a pixel.\n",
    "\n",
    "<figure>\n",
    "    <center>\n",
    "        <img src=\"attachments/ct-scan-voxel-example.png\"  style=\"width:550px;\" >\n",
    "        <p><small>A CT scan of a human torso showing, from the top, skin, organs, spine, and patient support bed.</small></p>\n",
    "    </center>\n",
    "</figure>\n",
    "\n",
    "### Voxel\n",
    "\n",
    "> **Voxel - Volumetric pixel** is the 3D equivalent to the familiar two-dimensional pixel. It encloses a volume of space.\n",
    "\n",
    "Each voxel of a CT scan has a numeric value that roughly corresponds to the average mass density of the matter contained inside. Most visualizations of that data show high-density material like bones and metal implants as white, low-density air and lung tissue as black, and fat and tissue as various shades of gray.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodule\n",
    "\n",
    "A nodule is any of the myriad lumps and bumps that might appear inside someone’s lungs. Some are problematic from a health-of-the-patient perspective; some are not. The precise definition limits the size of a nodule to 3 cm or less, with a larger lump being a lung mass; but we’re going to use nodule interchangeably for all such anatomical structures. A nodule can turn out to be benign or a malignant tumor (also referred to as cancer). From a radiological perspective, a nodule is really similar to other lumps that have a wide variety of causes: infection, inflammation, blood-supply issues, malformed blood vessels, and diseases other than tumors.\n",
    "\n",
    "<figure>\n",
    "    <center>\n",
    "        <img src=\"attachments/malignant-nodule.png\"  style=\"width:750px;\" >\n",
    "    </center>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An end-to-end project design\n",
    "\n",
    "Our lung cancer diagnosis pipeline uses five key steps:\n",
    "\n",
    "1. Data Loading: Convert raw CT scans into PyTorch-compatible format.\n",
    "2. Segmentation:Detect tumor-associated voxels in lung regions using segmentation models.\n",
    "3. Grouping: Cluster voxels into candidate nodules and identify their 3D centers (non-ML step).\n",
    "4. Classification: Analyze 3D regions around candidate nodules using convolutional networks to predict malignancy.\n",
    "5. Diagnosis: Aggregate nodule predictions, using maximum malignancy score for final diagnosis.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
